---
title: "Programación Distribuida con MPI"
description: "Fundamentos prácticos de programación paralela en arquitecturas de memoria distribuida utilizando MPI. Aprende a comunicar procesos, usar tipos de datos MPI y calcular PI en paralelo."
pubDate: "2025-04-04"
author: "Railly Hugo"
authorImageUrl: "/hugo-profile.webp"
dueDate: "2025-04-10"
files: ["HelloWorldMPI_01.cpp"]
path: "Laboratory/MPI"
---

import Alert from "../../../components/Alert.astro";
import CodeBlock from "../../../components/CodeBlock.astro";
import Card from "../../../components/Card.astro";

Este laboratorio tiene como objetivo familiarizarte con la programación distribuida usando MPI (Message Passing Interface). Aprenderás a:

- Crear programas MPI básicos
- Comunicar datos entre procesos
- Implementar operaciones colectivas
- Manejar diferentes tipos de datos en MPI

Esta práctica servirá como base para experimentos posteriores relacionados con rendimiento, modelos de memoria y eficiencia en cómputo distribuido.


## Problema

### Memoria Distribuida vs Compartida

#### Memoria Distribuida
- Colección de pares núcleo-memoria conectados por una red
- La memoria asociada a cada núcleo solo es accesible para ese núcleo
- Diferentes procesos

#### Memoria Compartida
- Colección de pares núcleo-memoria conectados por una memoria globalmente accesible
- Cada núcleo puede acceder a cualquier ubicación de memoria
- Diferentes hilos dentro del mismo proceso

### Funciones MPI Básicas

| Función | Propósito | Analogía |
|---------|-----------|----------|
| `MPI_Comm_size` | Obtener número de procesos | "¿Qué tan grande es este equipo?" |
| `MPI_Comm_rank` | Obtener rango del proceso actual | "¿Cuál es mi número de jersey?" |
| `MPI_Send` | Enviar datos a otro proceso | "Enviar un mensaje" |
| `MPI_Recv` | Recibir datos de otro proceso | "Recibir un mensaje" |
| `MPI_Bcast` | Difundir datos a todos los procesos | "Anunciar a todos" |
| `MPI_Reduce` | Reducir datos de todos los procesos | "Combinar resultados" |

## Requisitos

- Entregar los archivos fuente de los ejercicios completados
- El programa debe compilar y ejecutar correctamente en la plataforma especificada
- Documentar los resultados y observaciones

## Código Base

<div class="grid gap-4 md:grid-cols-2">
  <Card
    title="1. Hello World MPI (Básico)"
    description="Tu primer programa MPI que muestra el rango de cada proceso"
    href="https://github.com/FISI-SM/ParallelProgramming-repo/blob/main/Laboratory/MPI_code/prog01_HelloWorldMPI_01/HelloWorldMPI_01.c"
  />

  <Card
    title="2. Hello World MPI (Avanzado)"
    description="Versión mejorada del Hello World con más detalles de proceso"
    href="https://github.com/FISI-SM/ParallelProgramming-repo/blob/main/Laboratory/MPI_code/prog02_HelloWorldMPI_02/HelloWorldMPI_02.c"
  />

  <Card
    title="3. Envío de Mensajes (Básico)"
    description="Implementa comunicación básica entre procesos usando MPI_Send y MPI_Recv"
    href="https://github.com/FISI-SM/ParallelProgramming-repo/blob/main/Laboratory/MPI_code/prog03_SendMessage01/SendMessage01.c"
  />

  <Card
    title="4. Envío de Mensajes (Avanzado)"
    description="Implementación avanzada de comunicación entre procesos"
    href="https://github.com/FISI-SM/ParallelProgramming-repo/blob/main/Laboratory/MPI_code/prog04.1_SendMessage02/SendMessage02.c"
  />

  <Card
    title="5. Traductor MPI"
    description="Implementa un traductor simple usando comunicación MPI"
    href="https://github.com/FISI-SM/ParallelProgramming-repo/blob/main/Laboratory/MPI_code/prog04.2_SendMessage03Traductor/SendMessageTraductor.c"
  />

  <Card
    title="6. Tipos de Datos MPI"
    description="Explora diferentes tipos de datos en comunicación MPI"
    href="https://github.com/FISI-SM/ParallelProgramming-repo/blob/main/Laboratory/MPI_code/prog04.3_SendMessage04AllTypes/SendMessageAllTypes.c"
  />

  <Card
    title="7. Cálculo de PI (Secuencial)"
    description="Versión secuencial del cálculo de PI para comparación"
    href="https://github.com/FISI-SM/ParallelProgramming-repo/blob/main/Laboratory/MPI_code/prog05.0_CalculoPI/CalculoPI_Secuencial.c"
  />

  <Card
    title="8. Cálculo de PI (Paralelo)"
    description="Implementa el cálculo de PI usando MPI"
    href="https://github.com/FISI-SM/ParallelProgramming-repo/blob/main/Laboratory/MPI_code/prog05.0_CalculoPI/CalculoPI.c"
  />
</div>

## Instalación de MPI

### En macOS/Linux

#### macOS usando Homebrew
```bash
# Instalar Homebrew si no está instalado
/bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"

# Instalar Open MPI
brew install open-mpi
```

#### Linux (Ubuntu/Debian)
```bash
# Actualizar repositorios
sudo apt update

# Instalar Open MPI y compiladores
sudo apt install openmpi-bin libopenmpi-dev
```

Para verificar la instalación:
```bash
# Verificar versión de MPI
mpirun --version

# Verificar que el compilador está disponible
mpicc --version
```

### Instalación en Windows

#### Paso 0: Instalar MINGW y GCC

1. Descargue e instale MINGW desde [aquí](https://code.visualstudio.com/docs/cpp/config-mingw).
2. Siga las instrucciones en la página para instalar MINGW y GCC.
3. Verifique la instalación de GCC escribiendo el comando `gcc --version` en la terminal.

#### Paso 1: Instalar WSL y Ubuntu

1. Abra Microsoft Store y busque "Ubuntu"
2. Instale la versión más reciente de Ubuntu
3. Abra Windows Terminal (puede buscarlo en el menú inicio)
4. En la terminal, abra una nueva instancia de Ubuntu
5. Durante la primera ejecución, se le pedirá crear un usuario:
   - Elija el nombre de usuario que desee
   - Establezca la contraseña como: `FISI2024`

#### Paso 2: Instalar MPI en Ubuntu

Una vez dentro de la terminal de Ubuntu, ejecute los siguientes comandos:

```bash
# Actualizar repositorios
sudo apt update

# Instalar Open MPI y compiladores
sudo apt install openmpi-bin openmpi-common libopenmpi-dev
```

#### Paso 3: Verificar la instalación

```bash
# Verificar que el compilador está disponible
mpicc --version

# Verificar que MPI está instalado
mpirun --version
```

#### Paso 4: Clonar el repositorio

```bash
# Crear directorio de proyectos
mkdir projects
cd projects

# Clonar el repositorio
git clone https://github.com/FISI-SM/ParallelProgramming-repo.git

# Entrar al directorio MPI
cd ParallelProgramming-repo/Laboratory/MPI_code
```
## Compilación y Ejecución

Una vez instalado MPI, puede compilar y ejecutar sus programas:

### Compilación
```bash
# Compilar un programa
mpicc -g -Wall -o out <program_name>.c 
```

### Ejecución
```bash
# Ejecutar con 4 procesos
mpiexec -n 4 <program_name>.exe
```

Notas importantes:
- El parámetro `-n` especifica el número de procesos
- En Windows, use la extensión `.exe`
- En Linux/macOS, asegúrese de que el archivo tenga permisos de ejecución (`chmod +x programa`)

## Plataforma de Evaluación
Este laboratorio se ejecuta de forma **local**. Actualmente en San Marcos no tenemos entorno remoto ni SSH, por lo tanto:

- Cada estudiante compilará y ejecutará su código en su propia máquina
- No se requiere submission por ahora. Guardar resultados para futuras prácticas

<Alert type="info">
  **Fecha de entrega sugerida:** 10 de abril de 2025. Asegúrate de completar todos los ejercicios y documentar tus resultados.
</Alert>


## Ejercicios Propuestos

<ul>
<li>
<a href="https://docs.google.com/document/d/1OssfLTNgNr0OeEUXlQG_hwc-k-vq2NKcUzZHAjUYSGk/edit?tab=t.0" target="_blank">Lab 02 - Google Drive</a>
</li>
</ul>

## Referencias
- [MPI Tutorial](https://mpitutorial.com/)
- [Open MPI Documentation](https://www.open-mpi.org/doc/)
- [MPI Reference](https://www.mpi-forum.org/docs/mpi-4.0/mpi40-report.pdf)
- [Microsoft MPI Documentation](https://learn.microsoft.com/en-us/message-passing-interface/microsoft-mpi)